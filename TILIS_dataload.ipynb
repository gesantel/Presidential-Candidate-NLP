{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab6dece-16e7-43d9-b20c-0266997d6611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: tensorflow in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: transformers in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: datasets in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (4.2.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/myenvironment/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e193e1-70d0-4f23-afdd-183f08729bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique tags on page:\n",
      "['html', 'ul', 'form', 'aside', 'button', 'li', 'p', 'label', 'head', 'img', 'body', 'script', 'h4', 'h2', 'title', 'meta', 'footer', 'section', 'link', 'span', 'nav', 'input', 'br', 'h3', 'strong', 'div', 'a']\n",
      "Found 18 debate links:\n",
      "https://www.presidency.ucsb.edu/documents/vice-presidential-debate-new-york-city\n",
      "https://www.presidency.ucsb.edu/people/other/presidential-candidate-debates\n",
      "https://www.presidency.ucsb.edu/documents/presidential-debate-philadelphia-pennsylvania\n",
      "https://www.presidency.ucsb.edu/people/other/presidential-candidate-debates\n",
      "https://www.presidency.ucsb.edu/documents/presidential-debate-atlanta-georgia\n",
      "https://www.presidency.ucsb.edu/documents/republican-candidates-debate-des-moines-iowa-1\n",
      "https://www.presidency.ucsb.edu/people/other/presidential-candidate-debates\n",
      "https://www.presidency.ucsb.edu/documents/republican-candidates-debate-tuscaloosa-alabama\n",
      "https://www.presidency.ucsb.edu/people/other/presidential-candidate-debates\n",
      "https://www.presidency.ucsb.edu/documents/republican-candidates-debate-miami-florida-0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#Scrape presidency.ucsb.edu website for debate links \n",
    "\n",
    "BASE_URL = \"https://www.presidency.ucsb.edu\"\n",
    "DEBATES_INDEX = f\"{BASE_URL}/documents/app-categories/elections-and-transitions/debates\"\n",
    "\n",
    "# Fetch index page\n",
    "resp = requests.get(DEBATES_INDEX)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "#See all available HTML Tags\n",
    "all_tags = [tag.name for tag in soup.find_all()]\n",
    "unique_tags = list(set(all_tags))  # find unique tags\n",
    "\n",
    "print(\"All unique tags on page:\")\n",
    "print(unique_tags)\n",
    "\n",
    "#Grab the URLs. They're found in a page's <a> tag, with an hfref attribute, we want those with debate in the href\n",
    "debate_links = []\n",
    "\n",
    "for a in soup.find_all(\"a\", href=True):\n",
    "    href = a[\"href\"]\n",
    "    \n",
    "# Check if \"debate\" in URL and year is between 2015-2024, don't want links to search links but to actual debate transcripts\n",
    "    if \"debate\" in href and \"app-categories\" not in href:\n",
    "        full_url = BASE_URL + href if href.startswith(\"/\") else href\n",
    "        debate_links.append(full_url)\n",
    "\n",
    "print(f\"Found {len(debate_links)} debate links:\")\n",
    "for link in debate_links[:10]:\n",
    "    print(link)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe890ad6-f68d-4606-90b5-be5965d1dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debates from 2015–2024: 10\n"
     ]
    }
   ],
   "source": [
    "#Grab speeches only between 2015-2024\n",
    "from datetime import datetime\n",
    "\n",
    "filtered_links = []\n",
    "\n",
    "for link in debate_links:\n",
    "    resp = requests.get(link)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "    date_tag = soup.find(\"span\", class_=\"date-display-single\")\n",
    "    if date_tag:\n",
    "        date_str = date_tag.get_text(strip=True)\n",
    "        try:\n",
    "            date_obj = datetime.strptime(date_str, \"%B %d, %Y\")  # e.g., 'October 19, 2016'\n",
    "            if 2015 <= date_obj.year <= 2024:\n",
    "                filtered_links.append(link)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(f\"Debates from 2015–2024: {len(filtered_links)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88e91ce-a8f0-4ec8-92ec-a0aede81a9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/10: https://www.presidency.ucsb.edu/documents/vice-presidential-debate-new-york-city\n",
      " Found participants: ['Senator J.D. Vance', 'Governor Tim Walz']\n",
      "Extracted 97 lines for Vice Presidential Debate in New York City\n",
      "\n",
      "Processing 2/10: https://www.presidency.ucsb.edu/documents/presidential-debate-philadelphia-pennsylvania\n",
      " Found participants: ['Vice President Kamala Harris', 'Former President Donald Trump']\n",
      "Extracted 105 lines for Presidential Debate in Philadelphia, Pennsylvania\n",
      "\n",
      "Processing 3/10: https://www.presidency.ucsb.edu/documents/presidential-debate-atlanta-georgia\n",
      " Found participants: ['President Joe Biden', 'Former President Donald Trump']\n",
      "Extracted 97 lines for Presidential Debate in Atlanta, Georgia\n",
      "\n",
      "Processing 4/10: https://www.presidency.ucsb.edu/documents/republican-candidates-debate-des-moines-iowa-1\n",
      " Found participants: ['Governor Ron DeSantis;', 'Former Governor Nikki Haley;']\n",
      "Extracted 176 lines for Republican Candidates Debate in Des Moines, Iowa\n",
      "\n",
      "Processing 5/10: https://www.presidency.ucsb.edu/documents/republican-candidates-debate-tuscaloosa-alabama\n",
      " Found participants: ['Former Governor Chris Christie;', 'Governor Ron DeSantis;', 'Former Governor Nikki Haley;', 'Vivek Ramaswamy']\n",
      "Extracted 234 lines for Republican Candidates Debate in Tuscaloosa, Alabama\n",
      "\n",
      "Processing 6/10: https://www.presidency.ucsb.edu/documents/republican-candidates-debate-miami-florida-0\n",
      " Found participants: ['Former Governor Chris Christie;', 'Governor Ron DeSantis;', 'Former Governor Nikki Haley;', 'Vivek Ramaswamy;', 'Senator Tim Scott;']\n",
      "Extracted 133 lines for Republican Candidates Debate in Miami, Florida\n",
      "\n",
      "Processing 7/10: https://www.presidency.ucsb.edu/documents/republican-candidates-debate-simi-valley-california-1\n",
      " Found participants: ['Governor Doug Burgum;', 'Former Governor Chris Christie;', 'Governor Ron DeSantis;', 'Former Governor Nikki Haley;', 'Former Vice President Mike Pence;', 'Vivek Ramaswamy;', 'Senator Tim Scott;']\n",
      "Extracted 276 lines for Republican Candidates Debate in Simi Valley, California\n",
      "\n",
      "Processing 8/10: https://www.presidency.ucsb.edu/documents/republican-candidates-debate-milwaukee-wisconsin-0\n",
      " Found participants: ['Governor Doug Burgum;', 'Former Governor Chris Christie;', 'Governor Ron DeSantis;', 'Former Governor Nikki Haley;', 'Former Governor Asa Hutchinson;', 'Former Vice President Mike Pence;', 'Vivek Ramaswamy;', 'Senator Tim Scott;']\n",
      "Extracted 271 lines for Republican Candidates Debate in Milwaukee, Wisconsin\n",
      "\n",
      "Processing 9/10: https://www.presidency.ucsb.edu/documents/presidential-debate-belmont-university-nashville-tennessee-0\n",
      " Found participants: ['Former Vice President Joe Biden', 'President Donald Trump']\n",
      "Extracted 206 lines for Presidential Debate at Belmont University in Nashville, Tennessee\n",
      "\n",
      "Processing 10/10: https://www.presidency.ucsb.edu/documents/vice-presidential-debate-the-university-utah-salt-lake-city\n",
      " Found participants: ['Senator Kamala Harris', 'Vice President Mike Pence']\n",
      "Extracted 151 lines for Vice Presidential Debate the University of Utah in Salt Lake City\n",
      "\n",
      "All debates collected: 10 unique debates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate_id</th>\n",
       "      <th>debate_title</th>\n",
       "      <th>debate_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Walz</td>\n",
       "      <td>Well, thank you. And thank you for those joini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Vance</td>\n",
       "      <td>So, Margaret, I want to answer the question. F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Walz</td>\n",
       "      <td>Well, look, Donald Trump was in office. We'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Vance</td>\n",
       "      <td>Well, first of all, Margaret, diplomacy is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Vance</td>\n",
       "      <td>Sure. So first of all, let's start with the hu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   debate_id                               debate_title       debate_date  \\\n",
       "0          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "1          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "2          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "3          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "4          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "\n",
       "  speaker                                               text  \n",
       "0    Walz  Well, thank you. And thank you for those joini...  \n",
       "1   Vance  So, Margaret, I want to answer the question. F...  \n",
       "2    Walz  Well, look, Donald Trump was in office. We'll ...  \n",
       "3   Vance  Well, first of all, Margaret, diplomacy is not...  \n",
       "4   Vance  Sure. So first of all, let's start with the hu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "BASE_URL = \"https://www.presidency.ucsb.edu\"\n",
    "debates_data = []\n",
    "\n",
    "for idx, link in enumerate(filtered_links):\n",
    "    print(f\"Processing {idx+1}/{len(filtered_links)}: {link}\")\n",
    "    resp = requests.get(link)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "    # Extract debate title\n",
    "    title_tag = soup.find(\"h1\")\n",
    "    title = title_tag.get_text(strip=True) if title_tag else \"Unknown Debate\"\n",
    "    \n",
    "    # Extract date\n",
    "    date_tag = soup.find(\"span\", class_=\"date-display-single\")\n",
    "    date = date_tag.get_text(strip=True) if date_tag else \"\"\n",
    "    \n",
    "    # Extract participants\n",
    "    participants_b = soup.find(\"b\", string=re.compile(r\"PARTICIPANTS\", re.I))\n",
    "    participants = []\n",
    "    if participants_b:\n",
    "        # Collect text following the <b>PARTICIPANTS:</b> tag until MODERATORS\n",
    "        text_parts = []\n",
    "        for sib in participants_b.next_siblings:\n",
    "            if sib.name == \"b\" and \"MODERATOR\" in sib.get_text(strip=True).upper():\n",
    "                break\n",
    "            if isinstance(sib, str):\n",
    "                text_parts.append(sib.strip())\n",
    "            elif sib.name == \"br\":\n",
    "                text_parts.append(\"\\n\")\n",
    "            elif sib.name:\n",
    "                text_parts.append(sib.get_text(\" \", strip=True))\n",
    "        combined = \" \".join(text_parts)\n",
    "        # Split by 'and' or newline, remove empty and trailing pieces\n",
    "        raw_names = re.split(r\"\\band\\b|\\n\", combined)\n",
    "        for name in raw_names:\n",
    "            name = name.strip().strip(\",\").strip()\n",
    "            if name:\n",
    "                # Extract name part before parentheses (D)/(R)\n",
    "                clean_name = re.sub(r\"\\s*\\([^)]*\\)\", \"\", name).strip()\n",
    "                if clean_name:\n",
    "                    participants.append(clean_name)\n",
    "    print(f\" Found participants: {participants}\")\n",
    "    \n",
    "    # Extract transcript lines\n",
    "    speech = []\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    for p in paragraphs:\n",
    "        b = p.find(\"b\")\n",
    "        if b:\n",
    "            speaker_raw = b.get_text(strip=True).rstrip(\":\").upper()\n",
    "            # Match if speaker is one of the participants by last name\n",
    "            if any(speaker_raw in name.upper() for name in participants):\n",
    "                # Remove <b> tag and get rest of text\n",
    "                b.extract()\n",
    "                text = p.get_text(\" \", strip=True)\n",
    "                if text:\n",
    "                    speech.append({\n",
    "                        \"debate_id\": idx + 1,\n",
    "                        \"debate_title\": title,\n",
    "                        \"debate_date\": date,\n",
    "                        \"speaker\": speaker_raw.title(),\n",
    "                        \"text\": text\n",
    "                    })\n",
    "    print(f\"Extracted {len(speech)} lines for {title}\\n\")\n",
    "    debates_data.extend(speech)\n",
    "\n",
    "    time.sleep(1) # Being nice to server\n",
    "\n",
    "\n",
    "# Convert to dataframe \n",
    "df_debates = pd.DataFrame(debates_data)\n",
    "print(\"All debates collected:\", df_debates[\"debate_title\"].nunique(), \"unique debates\")\n",
    "df_debates.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d7647d-21d6-40f5-b2c4-3cb377ffc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(row):\n",
    "    speaker = row[\"speaker\"]\n",
    "    text = row[\"text\"]\n",
    "\n",
    "    # Remove speaker name repetition at start (e.g. \"Kamala Harris:\" or \"HARRIS - \")\n",
    "    pattern = re.compile(rf\"^{speaker}[\\.\\:\\-\\s]+\", re.IGNORECASE)\n",
    "    text = pattern.sub(\"\", text)\n",
    "\n",
    "    # Remove parenthetical notes like (applause), [laughter], (inaudible)\n",
    "    text = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "\n",
    "    # Collapse all whitespace, tabs, and line breaks into single spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Trim leading/trailing spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Apply to DataFrame\n",
    "df_debates[\"text\"] = df_debates.apply(clean_text, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6388a4d8-a6c7-41e1-9c95-40165f7d226c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_debates.to_csv(\"TILIS.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a55637-1df1-421f-a639-5816b591bd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ecb33-1ffc-4124-886e-94509256abc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

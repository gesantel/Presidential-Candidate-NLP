{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96c3a3f8-aa4b-42de-9a89-8e10be960626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (2.3.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/hf/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df751917-4250-430f-9dc8-b5279c2fecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from collections import Counter\n",
    "import re\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings, logging, torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98da0626-4105-412a-8932-56ce4dda6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TIL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d7f0cb6-78fb-4aec-8320-a01358eb557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'label':'sentiment'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d82cae-4416-428b-bc57-a1128caf4948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate_id</th>\n",
       "      <th>debate_title</th>\n",
       "      <th>debate_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>i_count</th>\n",
       "      <th>we_count</th>\n",
       "      <th>he_count</th>\n",
       "      <th>he_per_1000</th>\n",
       "      <th>we_per_1000</th>\n",
       "      <th>i_per_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Walz</td>\n",
       "      <td>Well, thank you. And thank you for those joini...</td>\n",
       "      <td>319.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.993426</td>\n",
       "      <td>well, thank you. and thank you for those joini...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>21.87500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Vance</td>\n",
       "      <td>So, Margaret, I want to answer the question. F...</td>\n",
       "      <td>450.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.994194</td>\n",
       "      <td>so, margaret, i want to answer the question. f...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.217295</td>\n",
       "      <td>8.86918</td>\n",
       "      <td>26.607539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   debate_id                               debate_title       debate_date  \\\n",
       "0          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "1          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "\n",
       "  speaker                                               text  word_count  \\\n",
       "0    Walz  Well, thank you. And thank you for those joini...       319.0   \n",
       "1   Vance  So, Margaret, I want to answer the question. F...       450.0   \n",
       "\n",
       "  sentiment     score                                         text_lower  \\\n",
       "0  positive  0.993426  well, thank you. and thank you for those joini...   \n",
       "1  positive  0.994194  so, margaret, i want to answer the question. f...   \n",
       "\n",
       "   i_count  we_count  he_count  he_per_1000  we_per_1000  i_per_1000  \n",
       "0        0         7         5    15.625000     21.87500    0.000000  \n",
       "1       12         4         1     2.217295      8.86918   26.607539  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30aeb209-40ba-4dee-9b6b-1251988f01eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "np.set_printoptions(precision = 2, suppress = True)\n",
    "\n",
    "model_nm = \"distilroberta-base\"\n",
    "toker = AutoTokenizer.from_pretrained(model_nm)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=2, problem_type=\"single_label_classification\")\n",
    "\n",
    "model.config.hidden_dropout_prob = 0.2\n",
    "model.config.attention_probs_dropout_prob = 0.2\n",
    "\n",
    "sep = toker.sep_token\n",
    "cls = toker.cls_token \n",
    "pad = toker.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "580d5b5e-5d4f-40e3-9fa1-4a81639a4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"debate_id\"]).reset_index(drop=True)\n",
    "df['sen_tok'] = '<' + df.sentiment +'>'\n",
    "\n",
    "df[\"prev_speaker\"] = df.groupby(\"debate_id\")[\"speaker\"].shift(1)\n",
    "df[\"prev_text\"] = df.groupby(\"debate_id\")[\"text_lower\"].shift(1)\n",
    "df[\"prev_sentiment\"] = df.groupby(\"debate_id\")[\"sen_tok\"].shift(1)\n",
    "\n",
    "df[\"prev_sentiment\"] = df[\"prev_sentiment\"].fillna(\"<NO PREVIOUS SPEAKER>\").astype(str)\n",
    "df[\"prev_text\"] = df[\"prev_text\"].fillna(\"<NO PREVIOUS SPEAKER>\").astype(str)\n",
    "df[\"prev_speaker\"] = df[\"prev_speaker\"].fillna(\"<NO PREVIOUS SPEAKER>\").astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86bd33f5-627b-4fe1-a633-fe97d49af3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate_id</th>\n",
       "      <th>debate_title</th>\n",
       "      <th>debate_date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>i_count</th>\n",
       "      <th>we_count</th>\n",
       "      <th>he_count</th>\n",
       "      <th>he_per_1000</th>\n",
       "      <th>we_per_1000</th>\n",
       "      <th>i_per_1000</th>\n",
       "      <th>sen_tok</th>\n",
       "      <th>prev_speaker</th>\n",
       "      <th>prev_text</th>\n",
       "      <th>prev_sentiment</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Walz</td>\n",
       "      <td>Well, thank you. And thank you for those joini...</td>\n",
       "      <td>319.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.993426</td>\n",
       "      <td>well, thank you. and thank you for those joini...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15.625</td>\n",
       "      <td>21.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;positive&gt;</td>\n",
       "      <td>&lt;NO PREVIOUS SPEAKER&gt;</td>\n",
       "      <td>&lt;NO PREVIOUS SPEAKER&gt;</td>\n",
       "      <td>&lt;NO PREVIOUS SPEAKER&gt;</td>\n",
       "      <td>Vice Presidential Debate in New York City&lt;/s&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vice Presidential Debate in New York City</td>\n",
       "      <td>October 01, 2024</td>\n",
       "      <td>Walz</td>\n",
       "      <td>I'm going to respond on the pro-abortion piece...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.769513</td>\n",
       "      <td>i'm going to respond on the pro-abortion piece...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>76.530612</td>\n",
       "      <td>5.102041</td>\n",
       "      <td>&lt;positive&gt;</td>\n",
       "      <td>Walz</td>\n",
       "      <td>well, thank you. and thank you for those joini...</td>\n",
       "      <td>&lt;positive&gt;</td>\n",
       "      <td>Vice Presidential Debate in New York City&lt;/s&gt;w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   debate_id                               debate_title       debate_date  \\\n",
       "0          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "1          1  Vice Presidential Debate in New York City  October 01, 2024   \n",
       "\n",
       "  speaker                                               text  word_count  \\\n",
       "0    Walz  Well, thank you. And thank you for those joini...       319.0   \n",
       "1    Walz  I'm going to respond on the pro-abortion piece...       195.0   \n",
       "\n",
       "  sentiment     score                                         text_lower  \\\n",
       "0  positive  0.993426  well, thank you. and thank you for those joini...   \n",
       "1  positive  0.769513  i'm going to respond on the pro-abortion piece...   \n",
       "\n",
       "   i_count  we_count  he_count  he_per_1000  we_per_1000  i_per_1000  \\\n",
       "0        0         7         5       15.625    21.875000    0.000000   \n",
       "1        1        15         0        0.000    76.530612    5.102041   \n",
       "\n",
       "      sen_tok           prev_speaker  \\\n",
       "0  <positive>  <NO PREVIOUS SPEAKER>   \n",
       "1  <positive>                   Walz   \n",
       "\n",
       "                                           prev_text         prev_sentiment  \\\n",
       "0                              <NO PREVIOUS SPEAKER>  <NO PREVIOUS SPEAKER>   \n",
       "1  well, thank you. and thank you for those joini...             <positive>   \n",
       "\n",
       "                                               input  \n",
       "0  Vice Presidential Debate in New York City</s><...  \n",
       "1  Vice Presidential Debate in New York City</s>w...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe6dcb06-e363-45a4-b4a5-338a0492684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/l7pys41d4n3crmy5xf_sgrmm0000gn/T/ipykernel_21957/624025835.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['labels'] = le.fit_transform(train_df['speaker'])\n",
      "/var/folders/gg/l7pys41d4n3crmy5xf_sgrmm0000gn/T/ipykernel_21957/624025835.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_df['labels'] = le.transform(eval_df['speaker'])\n",
      "Map: 100%|█████████████████████████████| 97/97 [00:00<00:00, 2227.73 examples/s]\n",
      "Casting the dataset: 100%|██████████| 206/206 [00:00<00:00, 22250.95 examples/s]\n",
      "Casting the dataset: 100%|████████████| 97/97 [00:00<00:00, 24004.22 examples/s]\n",
      "Map: 100%|███████████████████████████| 144/144 [00:00<00:00, 1604.54 examples/s]\n",
      "Map: 100%|█████████████████████████████| 62/62 [00:00<00:00, 7681.65 examples/s]\n",
      "Map: 100%|████████████████████████████| 97/97 [00:00<00:00, 10433.32 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([1.2203, 0.8471], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Input column\n",
    "#df['input'] = df['debate_title']+  df['prev_text'] + df['prev_sentiment'] + df['text_lower'] + df['sen_tok']\n",
    "df['input'] = df['debate_title']+ df['text_lower'] + df['sen_tok']\n",
    "\n",
    "# Tokenization function and special Tokens\n",
    "special_tokens = list(df['sen_tok'].unique())\n",
    "toker.add_special_tokens({'additional_special_tokens': special_tokens})\n",
    "\n",
    "model.resize_token_embeddings(len(toker))\n",
    "\n",
    "\n",
    "def tok_func(batch):\n",
    "    texts = [str(x) if x is not None and x == x else \"\" for x in batch[\"input\"]]\n",
    "    return toker(texts, truncation=True, padding=\"max_length\",max_length=200)\n",
    "    \n",
    "#Set Train and Evaluation Data\n",
    "train_df = df[df['debate_title'] == 'Presidential Debate at Belmont University in Nashville, Tennessee']\n",
    "eval_df  = df[df['debate_title'] == 'Presidential Debate in Atlanta, Georgia']\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_df['labels'] = le.fit_transform(train_df['speaker'])\n",
    "eval_df['labels'] = le.transform(eval_df['speaker'])\n",
    "\n",
    "#Convert to HuggingFace Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "eval_ds = eval_ds.map(lambda x: {'input': str(x['input'])})\n",
    "\n",
    "#Make 'Biden,' 'Trump' classes and cast\n",
    "class_names = le.classes_.tolist()  \n",
    "class_label = ClassLabel(names = class_names)\n",
    "\n",
    "train_ds = train_ds.cast_column(\"labels\", class_label)\n",
    "eval_ds = eval_ds.cast_column(\"labels\", class_label)\n",
    "\n",
    "# Train Test Split\n",
    "unnecc_columns = ['debate_id', 'debate_title', 'debate_date', 'speaker', 'text',\n",
    "       'word_count', 'sentiment', 'score', 'text_lower', 'i_count', 'we_count',\n",
    "       'he_count', 'he_per_1000', 'we_per_1000', 'i_per_1000', 'sen_tok',\n",
    "       'prev_speaker', 'prev_text', 'prev_sentiment', 'input']\n",
    "\n",
    "\n",
    "train_test_split = train_ds.train_test_split(test_size=0.3, seed=1, stratify_by_column='labels')\n",
    "train_ds_split = train_test_split['train']\n",
    "test_ds_split  = train_test_split['test']\n",
    "\n",
    "train_tok = train_ds_split.map(tok_func, batched = True, remove_columns = unnecc_columns)\n",
    "test_tok = test_ds_split.map(tok_func, batched = True, remove_columns = unnecc_columns)\n",
    "eval_tok = eval_ds.map(tok_func, batched=True, remove_columns = unnecc_columns)\n",
    "\n",
    "#Add weights do to inbalance\n",
    "y = train_tok['labels']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c86043b5-402f-47af-a228-1443fdfbecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/hf/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 13:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.639750</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.671665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.628945</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.674943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.615351</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.660092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/hf/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/miniconda3/envs/hf/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=0.5788856612311469, metrics={'train_runtime': 841.2855, 'train_samples_per_second': 0.513, 'train_steps_per_second': 0.043, 'total_flos': 22353873523200.0, 'train_loss': 0.5788856612311469, 'epoch': 3.0})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs[\"labels\"].to(model.device)\n",
    "        #labels = torch.tensor(inputs.get('labels'), dtype=torch.long).to(device)       \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = F.cross_entropy(logits, labels, weight= class_weights.to(device))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = np.array(labels)\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {\"recall\": recall, \"f1\": f1}\n",
    "\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"outputs\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,   \n",
    "    eval_strategy=\"epoch\",           \n",
    "    save_strategy=\"epoch\",           \n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "# Train and evaluate  \n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=test_tok,\n",
    "    processing_class=toker,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "        \n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03bc0b00-1f87-4d1a-9b33-ff0e1cd3d4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/hf/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6289454698562622, 'eval_recall': 0.6774193548387096, 'eval_f1': 0.6749434069043576, 'eval_runtime': 3.936, 'eval_samples_per_second': 15.752, 'eval_steps_per_second': 1.524, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/hf/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump' 'Trump' 'Trump' 'Biden' 'Trump' 'Biden' 'Trump' 'Trump' 'Trump'\n",
      " 'Biden' 'Biden' 'Trump' 'Biden' 'Trump' 'Trump' 'Biden' 'Trump' 'Biden'\n",
      " 'Trump' 'Trump']\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n",
    "\n",
    "#  Predictions  \n",
    "preds = trainer.predict(eval_tok).predictions   \n",
    "pred_labels = np.argmax(preds, axis=-1)       \n",
    "pred_speakers = le.inverse_transform(pred_labels)\n",
    "print(pred_speakers[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a417e641-535c-4e42-b2cb-60466ee8c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    speaker predicted_speaker  \\\n",
      "202   Trump             Trump   \n",
      "203   Biden             Trump   \n",
      "204   Trump             Trump   \n",
      "205   Trump             Biden   \n",
      "206   Trump             Trump   \n",
      "207   Biden             Biden   \n",
      "208   Biden             Trump   \n",
      "209   Biden             Trump   \n",
      "210   Trump             Trump   \n",
      "211   Trump             Biden   \n",
      "212   Trump             Biden   \n",
      "213   Trump             Trump   \n",
      "214   Trump             Biden   \n",
      "215   Biden             Trump   \n",
      "216   Biden             Trump   \n",
      "\n",
      "                                            text_lower  \n",
      "202  just to finish what he said, if i might, russi...  \n",
      "203  well, look, the greatest economy in the world,...  \n",
      "204                                         we'll see.  \n",
      "205  it's not going to drive them higher. it's just...  \n",
      "206    i didn't have sex with a porn star, number one.  \n",
      "207  he had the largest national debt of any presid...  \n",
      "208    folks, how are you? good to be here. thank you.  \n",
      "209  we've got to take a look at what i was left wh...  \n",
      "210  we had the greatest economy in the history of ...  \n",
      "211  well, he's right. he did beat medicare. he bea...  \n",
      "212  first of all, the supreme court just approved ...  \n",
      "213                                                NaN  \n",
      "214  there have been many young women murdered by t...  \n",
      "215  for 51 years, that was the law. fifty-one year...  \n",
      "216  i supported roe v. wade, which had three trime...  \n"
     ]
    }
   ],
   "source": [
    "eval_df = eval_df.copy()\n",
    "eval_df[\"predicted_speaker\"] = pred_speakers\n",
    "print(eval_df[[\"speaker\", \"predicted_speaker\", \"text_lower\"]].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "317308e6-4a49-4e23-a068-0c93cda36930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Biden       0.57      0.53      0.55        47\n",
      "       Trump       0.58      0.62      0.60        50\n",
      "\n",
      "    accuracy                           0.58        97\n",
      "   macro avg       0.58      0.58      0.58        97\n",
      "weighted avg       0.58      0.58      0.58        97\n",
      "\n",
      "[[25 22]\n",
      " [19 31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(eval_df[\"speaker\"], eval_df[\"predicted_speaker\"]))\n",
    "print(confusion_matrix(eval_df[\"speaker\"], eval_df[\"predicted_speaker\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hf)",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
